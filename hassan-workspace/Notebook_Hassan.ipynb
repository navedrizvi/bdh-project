{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The baseline model is trained using the following features:\n",
    "\n",
    "1) Diagnosis (value 1 for every diagnosis)\n",
    "\n",
    "2) Lab_results (value is the mean of recorded values, scaled by maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46520 unique patients in 46520 rows\n"
     ]
    }
   ],
   "source": [
    "### Sampling on patients\n",
    "path = \"../../data/\"\n",
    "patients = pd.read_csv(f\"{path}PATIENTS.csv\")\n",
    "#ensuring every patient is unique\n",
    "print(f\"{len(patients.SUBJECT_ID.unique())} unique patients in {len(patients)} rows\")\n",
    "#sampling random patients\n",
    "patients_sample = patients.sample(n = 10000, random_state= 1)\n",
    "# patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get admissions\n",
    "admissions = pd.read_csv(f\"{path}ADMISSIONS.csv.gz\")\n",
    "admissions = pd.merge(patients_sample.SUBJECT_ID,admissions)\n",
    "#admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "OBSERVATION_WINDOW = 365*2\n",
    "PREDICTION_WINDOW = 30\n",
    "USEFUL_COLUMNS = ['SUBJECT_ID','FEATURE','DATE','VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_events = pd.read_csv(\"../data/NOTEEVENTS.csv\")\n",
    "# #sample and save for these 1000 patients\n",
    "# note_events_sample = pd.merge(patients_sample.SUBJECT_ID,note_events)\n",
    "# note_events_sample.to_csv(\"../data/NOTEEVENTS_SAMPLE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Incomplete: Using AWS glue, for now I will do stuff locally\n",
    "# import boto3\n",
    "# Creating the low level functional client\n",
    "# client = boto3.client(\n",
    "#     'glue',\n",
    "#     aws_access_key_id = '',\n",
    "#     aws_secret_access_key = '',\n",
    "#     region_name = 'us-east-1'\n",
    "# )\n",
    "# clientResponse = client.get_table(DatabaseName=\"mimiciii\",Name=\"admissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_icd9(icd9_object):\n",
    "    \"\"\"\n",
    "    :param icd9_object: ICD-9 code (Pandas/Numpy object).\n",
    "    :return: extracted main digits of ICD-9 code\n",
    "    \"\"\"\n",
    "    icd9_str = str(icd9_object)\n",
    "\n",
    "    if icd9_str[0] == 'E': #if code starts with E\n",
    "        converted = icd9_str[:4]\n",
    "    else: #if they start with V or numeric\n",
    "        converted = icd9_str[:3]\n",
    "\n",
    "    return converted\n",
    "\n",
    "def build_codemap(dataset):\n",
    "    \"\"\"\n",
    "    :return: Dict of code map {main-digits of ICD9: unique feature ID}\n",
    "    \"\"\"\n",
    "    # TODO: We build a code map using ONLY train data. Think about how to construct validation/test sets using this.\n",
    "    df_digits = dataset['FEATURE'].unique()\n",
    "    codemap = {}\n",
    "    for i in range(0,len(df_digits)):\n",
    "        codemap[df_digits[i]] = i\n",
    "\n",
    "\n",
    "    return codemap\n",
    "\n",
    "# #dataset that contains HADM_ID\n",
    "# def filter_by_time_window(dataset,admissions,patients):\n",
    "#     dataset = pd.merge(dataset,admissions[['HADM_ID','ADMITTIME']],on = ['HADM_ID'])\n",
    "#     dataset = pd.merge(dataset,patients[['SUBJECT_ID','DOD']])\n",
    "#     dataset.loc[]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding diagnoses data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and etl on diagnoses\n",
    "diagnoses = pd.read_csv(f\"{path}DIAGNOSES_ICD.csv.gz\")\n",
    "# sample for the patients\n",
    "diagnoses = pd.merge(patients_sample.SUBJECT_ID,diagnoses)\n",
    "\n",
    "#add admit time to diagnosis \n",
    "diagnoses = diagnoses.merge(admissions[['HADM_ID','ADMITTIME']],on = 'HADM_ID')\n",
    "\n",
    "#convert features\n",
    "diagnoses['VALUE'] = 1\n",
    "diagnoses[\"ICD9_CODE\"] = diagnoses[\"ICD9_CODE\"].apply(convert_icd9).apply(lambda x: f\"DIAG_{x}\")\n",
    "diagnoses = diagnoses.rename(columns = {'ICD9_CODE':'FEATURE',\"ADMITTIME\":'DATE'})\n",
    "diagnoses = diagnoses[USEFUL_COLUMNS]\n",
    "\n",
    "diagnoses.drop_duplicates(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4074</td>\n",
       "      <td>DIAG_038</td>\n",
       "      <td>2204-02-04 07:26:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4074</td>\n",
       "      <td>DIAG_785</td>\n",
       "      <td>2204-02-04 07:26:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4074</td>\n",
       "      <td>DIAG_578</td>\n",
       "      <td>2204-02-04 07:26:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4074</td>\n",
       "      <td>DIAG_427</td>\n",
       "      <td>2204-02-04 07:26:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4074</td>\n",
       "      <td>DIAG_428</td>\n",
       "      <td>2204-02-04 07:26:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139065</th>\n",
       "      <td>62212</td>\n",
       "      <td>DIAG_790</td>\n",
       "      <td>2176-06-09 13:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139066</th>\n",
       "      <td>62212</td>\n",
       "      <td>DIAG_781</td>\n",
       "      <td>2176-06-09 13:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139067</th>\n",
       "      <td>62212</td>\n",
       "      <td>DIAG_338</td>\n",
       "      <td>2176-06-09 13:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139068</th>\n",
       "      <td>62212</td>\n",
       "      <td>DIAG_V15</td>\n",
       "      <td>2176-06-09 13:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139069</th>\n",
       "      <td>62212</td>\n",
       "      <td>DIAG_V49</td>\n",
       "      <td>2176-06-09 13:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128117 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID   FEATURE                 DATE  VALUE\n",
       "0             4074  DIAG_038  2204-02-04 07:26:00      1\n",
       "1             4074  DIAG_785  2204-02-04 07:26:00      1\n",
       "2             4074  DIAG_578  2204-02-04 07:26:00      1\n",
       "3             4074  DIAG_427  2204-02-04 07:26:00      1\n",
       "4             4074  DIAG_428  2204-02-04 07:26:00      1\n",
       "...            ...       ...                  ...    ...\n",
       "139065       62212  DIAG_790  2176-06-09 13:01:00      1\n",
       "139066       62212  DIAG_781  2176-06-09 13:01:00      1\n",
       "139067       62212  DIAG_338  2176-06-09 13:01:00      1\n",
       "139068       62212  DIAG_V15  2176-06-09 13:01:00      1\n",
       "139069       62212  DIAG_V49  2176-06-09 13:01:00      1\n",
       "\n",
       "[128117 rows x 4 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read and etl on lab_results\n",
    "# lab_results = pd.read_csv(f\"{path}LABEVENTS_SAMPLE.csv\")\n",
    "lab_results = pd.read_csv(f\"{path}LABEVENTS.csv.gz\")\n",
    "lab_results = pd.merge(patients_sample.SUBJECT_ID,lab_results)\n",
    "# lab_results.to_csv(\"LABEVENTS_SAMPLE.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_51279</td>\n",
       "      <td>2203-10-16 07:30:00</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_51301</td>\n",
       "      <td>2203-10-16 07:30:00</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_51221</td>\n",
       "      <td>2203-10-16 21:15:00</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_50868</td>\n",
       "      <td>2203-10-17 05:10:00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_50882</td>\n",
       "      <td>2203-10-17 05:10:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882837</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51250</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882838</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51265</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882839</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51277</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882840</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51279</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882841</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51301</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5882842 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID    FEATURE                 DATE VALUE\n",
       "0              4074  LAB_51279  2203-10-16 07:30:00  3.19\n",
       "1              4074  LAB_51301  2203-10-16 07:30:00   8.5\n",
       "2              4074  LAB_51221  2203-10-16 21:15:00  27.4\n",
       "3              4074  LAB_50868  2203-10-17 05:10:00    14\n",
       "4              4074  LAB_50882  2203-10-17 05:10:00    18\n",
       "...             ...        ...                  ...   ...\n",
       "5882837       62212  LAB_51250  2176-06-12 09:50:00    88\n",
       "5882838       62212  LAB_51265  2176-06-12 09:50:00   287\n",
       "5882839       62212  LAB_51277  2176-06-12 09:50:00  14.5\n",
       "5882840       62212  LAB_51279  2176-06-12 09:50:00  3.61\n",
       "5882841       62212  LAB_51301  2176-06-12 09:50:00   7.6\n",
       "\n",
       "[5882842 rows x 4 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#roughly 20% of these items have null in the HADM ID\n",
    "lab_results = lab_results.rename(columns = {'CHARTTIME':'DATE','ITEMID':'FEATURE'})\n",
    "#making sure lab_results has different item_id than diagnostics. appending a LAB to the itemIDs\n",
    "lab_results['FEATURE'] = lab_results['FEATURE'].apply(lambda x: f\"LAB_{x}\")\n",
    "lab_results = lab_results[USEFUL_COLUMNS]\n",
    "lab_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_51279</td>\n",
       "      <td>2203-10-16 07:30:00</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_51301</td>\n",
       "      <td>2203-10-16 07:30:00</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_51221</td>\n",
       "      <td>2203-10-16 21:15:00</td>\n",
       "      <td>27.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_50868</td>\n",
       "      <td>2203-10-17 05:10:00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4074</td>\n",
       "      <td>LAB_50882</td>\n",
       "      <td>2203-10-17 05:10:00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882837</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51250</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882838</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51265</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882839</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51277</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882840</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51279</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882841</th>\n",
       "      <td>62212</td>\n",
       "      <td>LAB_51301</td>\n",
       "      <td>2176-06-12 09:50:00</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5269315 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID    FEATURE                 DATE   VALUE\n",
       "0              4074  LAB_51279  2203-10-16 07:30:00    3.19\n",
       "1              4074  LAB_51301  2203-10-16 07:30:00    8.50\n",
       "2              4074  LAB_51221  2203-10-16 21:15:00   27.40\n",
       "3              4074  LAB_50868  2203-10-17 05:10:00   14.00\n",
       "4              4074  LAB_50882  2203-10-17 05:10:00   18.00\n",
       "...             ...        ...                  ...     ...\n",
       "5882837       62212  LAB_51250  2176-06-12 09:50:00   88.00\n",
       "5882838       62212  LAB_51265  2176-06-12 09:50:00  287.00\n",
       "5882839       62212  LAB_51277  2176-06-12 09:50:00   14.50\n",
       "5882840       62212  LAB_51279  2176-06-12 09:50:00    3.61\n",
       "5882841       62212  LAB_51301  2176-06-12 09:50:00    7.60\n",
       "\n",
       "[5269315 rows x 4 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take average value for lab_results\n",
    "lab_results = lab_results.dropna()\n",
    "#keep only numeric values, removing things like 'not done'\n",
    "def is_a_number(x):\n",
    "    try:\n",
    "        float(x.strip())\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "lab_results = lab_results.loc[lab_results['VALUE'].apply(is_a_number),:]\n",
    "lab_results['VALUE'] = pd.to_numeric(lab_results['VALUE'])\n",
    "\n",
    "#TODO: filter by date\n",
    "\n",
    "#keep average of values (can use more sophisticated methods later on)\n",
    "# lab_results = lab_results.groupby(['SUBJECT_ID','FEATURE']).mean().reset_index()\n",
    "lab_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microbiology Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4074</td>\n",
       "      <td>MB_90025_R</td>\n",
       "      <td>2200-09-24 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4074</td>\n",
       "      <td>MB_90016_R</td>\n",
       "      <td>2200-09-24 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4074</td>\n",
       "      <td>MB_90012_I</td>\n",
       "      <td>2200-09-24 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4074</td>\n",
       "      <td>MB_90002_R</td>\n",
       "      <td>2200-09-24 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4074</td>\n",
       "      <td>MB_90004_S</td>\n",
       "      <td>2204-01-16 04:44:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133781</th>\n",
       "      <td>28702</td>\n",
       "      <td>MB_90004_S</td>\n",
       "      <td>2160-08-17 06:20:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133782</th>\n",
       "      <td>28702</td>\n",
       "      <td>MB_90002_S</td>\n",
       "      <td>2160-08-17 06:20:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133783</th>\n",
       "      <td>28702</td>\n",
       "      <td>MB_90015_R</td>\n",
       "      <td>2160-08-17 06:20:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133784</th>\n",
       "      <td>28702</td>\n",
       "      <td>MB_90012_S</td>\n",
       "      <td>2160-08-17 06:20:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133786</th>\n",
       "      <td>28702</td>\n",
       "      <td>MB_90006_S</td>\n",
       "      <td>2160-08-17 06:20:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26459 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID     FEATURE                 DATE  VALUE\n",
       "2             4074  MB_90025_R  2200-09-24 01:00:00      1\n",
       "3             4074  MB_90016_R  2200-09-24 01:00:00      1\n",
       "5             4074  MB_90012_I  2200-09-24 01:00:00      1\n",
       "6             4074  MB_90002_R  2200-09-24 01:00:00      1\n",
       "20            4074  MB_90004_S  2204-01-16 04:44:00      1\n",
       "...            ...         ...                  ...    ...\n",
       "133781       28702  MB_90004_S  2160-08-17 06:20:00      1\n",
       "133782       28702  MB_90002_S  2160-08-17 06:20:00      1\n",
       "133783       28702  MB_90015_R  2160-08-17 06:20:00      1\n",
       "133784       28702  MB_90012_S  2160-08-17 06:20:00      1\n",
       "133786       28702  MB_90006_S  2160-08-17 06:20:00      1\n",
       "\n",
       "[26459 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### reading in data similar to lab_results, like microbiology events\n",
    "#NOTE: Does not seem to help at all\n",
    "mb_events = pd.read_csv(f\"{path}MICROBIOLOGYEVENTS.csv.gz\")\n",
    "mb_events = pd.merge(patients_sample.SUBJECT_ID,mb_events)\n",
    "mb_events = mb_events[['SUBJECT_ID','AB_ITEMID','INTERPRETATION','CHARTTIME']]\n",
    "mb_events.dropna(inplace= True)\n",
    "\n",
    "#transform seperate boolean values for Resistant, intermediate and Sensitive. \n",
    "mb_events = mb_events.loc[mb_events.INTERPRETATION != 'P']\n",
    "\n",
    "#keep only the last index in mb_events\n",
    "mb_events.drop_duplicates(subset = ['SUBJECT_ID','AB_ITEMID'], inplace = True,keep = 'last')\n",
    "\n",
    "mb_events['FEATURE'] = mb_events['AB_ITEMID'].apply(lambda x: f\"MB_{int(x)}_\") + mb_events.INTERPRETATION\n",
    "mb_events.drop('AB_ITEMID',axis = 1,inplace = True)\n",
    "\n",
    "mb_events.INTERPRETATION = 1\n",
    "mb_events.rename(columns = {'CHARTTIME':'DATE','INTERPRETATION':'VALUE'},inplace = True)\n",
    "mb_events = mb_events[USEFUL_COLUMNS]\n",
    "display(mb_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL on admissions\n",
    "\n",
    "\n",
    "#feature is the admission type and value is the time spent\n",
    "\n",
    "admissions['TIME_SPENT'] = pd.to_timedelta(pd.to_datetime(admissions.DISCHTIME)-  pd.to_datetime(admissions.ADMITTIME)).dt.total_seconds()/3600\n",
    "admissions['FEATURE'] = admissions.ADMISSION_TYPE.apply(lambda x: f\"ADM_{x[0:4]}\")\n",
    "admissions.rename(columns = {'TIME_SPENT':'VALUE','ADMITTIME': 'DATE'},inplace = True)\n",
    "\n",
    "admissions = admissions[USEFUL_COLUMNS]\n",
    "\n",
    "# admissions = admissions.groupby(['SUBJECT_ID','FEATURE']).aggregate('sum').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4074</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2200-09-15 02:08:00</td>\n",
       "      <td>281.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4074</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2204-01-05 10:48:00</td>\n",
       "      <td>270.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4074</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2204-02-04 07:26:00</td>\n",
       "      <td>42.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90889</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2153-02-05 11:21:00</td>\n",
       "      <td>348.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72753</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2129-04-05 16:40:00</td>\n",
       "      <td>69.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12656</th>\n",
       "      <td>21583</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2189-06-04 22:12:00</td>\n",
       "      <td>81.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12657</th>\n",
       "      <td>87048</td>\n",
       "      <td>ADM_ELEC</td>\n",
       "      <td>2118-09-12 14:00:00</td>\n",
       "      <td>121.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>16761</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2126-05-16 22:24:00</td>\n",
       "      <td>642.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>28702</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2160-07-30 19:43:00</td>\n",
       "      <td>903.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>62212</td>\n",
       "      <td>ADM_EMER</td>\n",
       "      <td>2176-06-09 13:01:00</td>\n",
       "      <td>100.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12661 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID   FEATURE                 DATE       VALUE\n",
       "0            4074  ADM_EMER  2200-09-15 02:08:00  281.650000\n",
       "1            4074  ADM_EMER  2204-01-05 10:48:00  270.533333\n",
       "2            4074  ADM_EMER  2204-02-04 07:26:00   42.233333\n",
       "3           90889  ADM_EMER  2153-02-05 11:21:00  348.633333\n",
       "4           72753  ADM_EMER  2129-04-05 16:40:00   69.950000\n",
       "...           ...       ...                  ...         ...\n",
       "12656       21583  ADM_EMER  2189-06-04 22:12:00   81.883333\n",
       "12657       87048  ADM_ELEC  2118-09-12 14:00:00  121.500000\n",
       "12658       16761  ADM_EMER  2126-05-16 22:24:00  642.600000\n",
       "12659       28702  ADM_EMER  2160-07-30 19:43:00  903.950000\n",
       "12660       62212  ADM_EMER  2176-06-09 13:01:00  100.433333\n",
       "\n",
       "[12661 rows x 4 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "This step will\n",
    "- merge all the features together\n",
    "- give them unique feature_ids by building a codemape\n",
    "- scale the features by their maximums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging diagnosis and lab_results\n",
    "# lab_results.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "# diagnoses.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "# mb_events.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "# admissions.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "\n",
    "features = pd.concat([lab_results,diagnoses,mb_events,admissions])\n",
    "\n",
    "#get rid of missing values\n",
    "features = features.dropna()\n",
    "\n",
    "#keep only observation_window\n",
    "# step 1: get index dates\n",
    "features['DATE'] = pd.to_datetime(features['DATE'])\n",
    "index_date = features[['SUBJECT_ID','DATE']].groupby(['SUBJECT_ID']).aggregate('max').reset_index()\n",
    "index_date = last_times.merge(patients[['SUBJECT_ID','DOD']])\n",
    "index_date.loc[index_date.DOD.notna(),'DATE'] = pd.to_datetime(index_date.DOD) - timedelta(days = PREDICTION_WINDOW)\n",
    "index_date = index_date.drop('DOD',axis = 1).rename(columns = {'DATE':'INDEX_DATE'})\n",
    "index_date['INDEX_DATE'] = pd.to_datetime(index_date['INDEX_DATE'])\n",
    "\n",
    "#step 2: create function to filter on features\n",
    "def process_data(features, index_date, function):\n",
    "    #filter\n",
    "    features = features.merge(index_date)\n",
    "    features['DATE'] = pd.to_datetime(features['DATE'])\n",
    "    features = features.loc[features.DATE<=features.INDEX_DATE] #lose observations above window\n",
    "    features = features.loc[features.DATE>=features.INDEX_DATE-timedelta(days = OBSERVATION_WINDOW)] #lose observations before window\n",
    "    features = features[['SUBJECT_ID','FEATURE','VALUE']]\n",
    "    \n",
    "    #aggregate\n",
    "    features = features.groupby(['SUBJECT_ID','FEATURE']).aggregate(function).reset_index()\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and aggregate features\n",
    "lab_results_processed = process_data(lab_results,index_date,np.mean)\n",
    "diagnoses_processed = process_data(diagnoses,index_date,np.mean)\n",
    "mb_events_processed = process_data(mb_events,index_date,np.mean)\n",
    "admissions_processed = process_data(admissions,index_date,np.sum)\n",
    "\n",
    "features =  pd.concat([lab_results_processed,diagnoses_processed,mb_events_processed,admissions_processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 1417\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>LAB_50802</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>LAB_50802</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>LAB_50802</td>\n",
       "      <td>0.094286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>LAB_50802</td>\n",
       "      <td>-0.373913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124</td>\n",
       "      <td>LAB_50802</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID    FEATURE     VALUE\n",
       "0          11  LAB_50802  0.100000\n",
       "1          71  LAB_50802 -0.400000\n",
       "2          96  LAB_50802  0.094286\n",
       "3         109  LAB_50802 -0.373913\n",
       "4         124  LAB_50802  0.300000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#scale features\n",
    "max_features = features.groupby(['FEATURE']).aggregate('max').reset_index()\n",
    "features = features.merge(max_features,on = 'FEATURE', suffixes=['', '_MAX'])\n",
    "features['VALUE'] = features['VALUE']/features['VALUE_MAX']\n",
    "features = features[['SUBJECT_ID','FEATURE','VALUE']]\n",
    "features = features.dropna()\n",
    "n_features = len(features.FEATURE.unique())+10\n",
    "print(f\"number of features: {n_features}\")\n",
    "display(features[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7190\n",
       "1    2810\n",
       "Name: DEAD, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SUBJECT_ID\n",
       "4074     1\n",
       "90889    0\n",
       "72753    0\n",
       "64908    0\n",
       "70273    0\n",
       "Name: DEAD, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create mortality table\n",
    "mortality = patients_sample.copy()\n",
    "mortality['DEAD'] = 1- mortality['DOD_SSN'].isna()\n",
    "mortality.index = mortality.SUBJECT_ID\n",
    "mortality = mortality['DEAD']\n",
    "display(mortality.value_counts())\n",
    "display(mortality[0:5])\n",
    "mortality = mortality.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data prior to model training\n",
    "The data will be saved in an SVM_light format for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_indices,test_indices = train_test_split(features['SUBJECT_ID'].unique(), test_size = 0.2, random_state = 1)\n",
    "\n",
    "train = features.loc[features.SUBJECT_ID.isin(train_indices)]\n",
    "test = features.loc[features.SUBJECT_ID.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Ivan's logic, removing features which only appear in training, and features that are below a minimum threshold\n",
    "feature_count = train[['FEATURE','VALUE']].groupby(['FEATURE']).aggregate('count').reset_index()\n",
    "acceptable_features = feature_count.loc[feature_count.VALUE > 1, 'FEATURE']\n",
    "n_features = len(acceptable_features)\n",
    "train = train.loc[train.FEATURE.isin(acceptable_features),:]\n",
    "test = test.loc[test.FEATURE.isin(acceptable_features),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 4126614 bytes for training\n",
      "wrote 993178 bytes for test\n"
     ]
    }
   ],
   "source": [
    "#apply codemap to features\n",
    "codemap = build_codemap(train)\n",
    "\n",
    "# function to help output data\n",
    "def create_svmlite(patient_features, mortality, output_type):\n",
    "    #apply codemap\n",
    "    patient_features['FEATURE'] = patient_features['FEATURE'].map(codemap)\n",
    "    patient_features['VALUE'] = patient_features.VALUE.round(6)\n",
    "\n",
    "    \n",
    "    #turn patient_features into an svm_light format kinda dictionaries\n",
    "    patient_features['F2V'] = list(zip(patient_features.FEATURE,patient_features.VALUE))\n",
    "    patient_features = patient_features.groupby(['SUBJECT_ID'])['F2V'].apply(list)\n",
    "    patient_features = patient_features.to_dict()\n",
    "\n",
    "    patient_ids = list(patient_features.keys())\n",
    "    patient_ids.sort()\n",
    "    d1 = \"\"\n",
    "    for id in patient_ids:\n",
    "        patient_features[id].sort()\n",
    "        features = ''\n",
    "        for feature in patient_features[id]:\n",
    "            features += f\" {str(int(feature[0]))}:\" + \"{:.6f}\".format(feature[1])\n",
    "        if output_type == 1: d1 += f\"{mortality[id]}{features} \\n\"\n",
    "        if output_type == 2: d1 += f\"{int(id)} {mortality[id]}{features} \\n\"\n",
    "\n",
    "    return d1\n",
    "\n",
    "train_file = open(f\"{path}svm_light/features.train\", 'wb')\n",
    "bytes_written = train_file.write(bytes((create_svmlite(train, mortality, 1)), 'UTF-8'))\n",
    "print(f\"wrote {bytes_written} bytes for training\")\n",
    "test_file = train_file = open(f\"{path}svm_light/features.test\", 'wb')\n",
    "bytes_written = train_file.write(bytes((create_svmlite(test, mortality, 1)), 'UTF-8'))\n",
    "print(f\"wrote {bytes_written} bytes for test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: Y_pred,Y_true\n",
    "# output: accuracy, auc, precision, recall, f1-score\n",
    "def classification_metrics(Y_pred, Y_true):\n",
    "    # TODO: Calculate the above mentioned metrics\n",
    "    acc = accuracy_score(Y_pred, Y_true)\n",
    "    auc_ = roc_auc_score(Y_pred, Y_true)\n",
    "    precision = precision_score(Y_pred, Y_true)\n",
    "    recall = recall_score(Y_pred, Y_true)\n",
    "    f1score = f1_score(Y_pred, Y_true)\n",
    "    # NOTE: It is important to provide the output in the same order\n",
    "    return acc, auc_, precision, recall, f1score\n",
    "# input: Name of classifier, predicted labels, actual labels\n",
    "def display_metrics(classifierName, Y_pred, Y_true):\n",
    "    print(\"______________________________________________\")\n",
    "    print((\"Classifier: \" + classifierName))\n",
    "    acc, auc_, precision, recall, f1score = classification_metrics(Y_pred, Y_true)\n",
    "    print((\"Accuracy: \" + str(acc)))\n",
    "    print((\"AUC: \" + str(auc_)))\n",
    "    print((\"Precision: \" + str(precision)))\n",
    "    print((\"Recall: \" + str(recall)))\n",
    "    print((\"F1-score: \" + str(f1score)))\n",
    "    print(\"______________________________________________\")\n",
    "    print(\"\")\n",
    "\n",
    "# input: X_train, Y_train and X_test\n",
    "# output: Y_pred\n",
    "def logistic_regression_pred(X_train, Y_train, X_test):\n",
    "    log_model = LogisticRegression(random_state=1)\n",
    "    log_model.fit(X_train, Y_train)\n",
    "    Y_pred = log_model.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "def random_forest_pred(X_train, Y_train, X_test):\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "X_train, Y_train = load_svmlight_file(f\"{path}svm_light/features.train\", n_features=n_features)\n",
    "X_test, Y_test = load_svmlight_file(f\"{path}svm_light/features.test\", n_features=n_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassan/opt/anaconda3/envs/Homework1/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.8826318909306461\n",
      "AUC: 0.7977444126967013\n",
      "Precision: 0.5551601423487544\n",
      "Recall: 0.6812227074235808\n",
      "F1-score: 0.611764705882353\n",
      "______________________________________________\n",
      "\n",
      "______________________________________________\n",
      "Classifier: Random Forest Tree\n",
      "Accuracy: 0.8772969768820391\n",
      "AUC: 0.8044381642622178\n",
      "Precision: 0.4412811387900356\n",
      "Recall: 0.7126436781609196\n",
      "F1-score: 0.545054945054945\n",
      "______________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "display_metrics(\"Logistic Regression\", logistic_regression_pred(X_train, Y_train, X_test), Y_test)\n",
    "# display_metrics(\"SVM\", svm_pred(X_train, Y_train, X_test), Y_test)\n",
    "display_metrics(\"Random Forest Tree\", random_forest_pred(X_train, Y_train, X_test), Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Homework1]",
   "language": "python",
   "name": "conda-env-Homework1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
