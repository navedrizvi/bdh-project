{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ym/7khf9p_j1ng4x68mby4sddq80000gp/T/ipykernel_77260/763495228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The baseline model is trained using the following features:\n",
    "\n",
    "1) Diagnosis (value 1 for every diagnosis)\n",
    "\n",
    "2) Lab_results (value is the mean of recorded values, scaled by maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "MIMIC_BUCKET = ''\n",
    "PATIENTS_S3_PATH = f's3://{MIMIC_BUCKET}/PATIENTS.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46520 unique patients in 46520 rows\n"
     ]
    }
   ],
   "source": [
    "### Sampling on patients\n",
    "import utils\n",
    "\n",
    "patients = pd.read_csv(f\"{path}PATIENTS.csv\")\n",
    "#ensuring every patient is unique\n",
    "print(f\"{len(patients.SUBJECT_ID.unique())} unique patients in {len(patients)} rows\")\n",
    "#sampling random patients\n",
    "patients_sample = patients.sample(n = 10000, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_events = pd.read_csv(\"../data/NOTEEVENTS.csv\")\n",
    "# #sample and save for these 1000 patients\n",
    "# note_events_sample = pd.merge(patients_sample.SUBJECT_ID,note_events)\n",
    "# note_events_sample.to_csv(\"../data/NOTEEVENTS_SAMPLE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Incomplete: Using AWS glue, for now I will do stuff locally\n",
    "# import boto3\n",
    "# Creating the low level functional client\n",
    "# client = boto3.client(\n",
    "#     'glue',\n",
    "#     aws_access_key_id = '',\n",
    "#     aws_secret_access_key = '',\n",
    "#     region_name = 'us-east-1'\n",
    "# )\n",
    "# clientResponse = client.get_table(DatabaseName=\"mimiciii\",Name=\"admissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_icd9(icd9_object):\n",
    "    \"\"\"\n",
    "    :param icd9_object: ICD-9 code (Pandas/Numpy object).\n",
    "    :return: extracted main digits of ICD-9 code\n",
    "    \"\"\"\n",
    "    icd9_str = str(icd9_object)\n",
    "\n",
    "    if icd9_str[0] == 'E': #if code starts with E\n",
    "        converted = icd9_str[:4]\n",
    "    else: #if they start with V or numeric\n",
    "        converted = icd9_str[:3]\n",
    "\n",
    "    return converted\n",
    "\n",
    "def build_codemap(dataset):\n",
    "    \"\"\"\n",
    "    :return: Dict of code map {main-digits of ICD9: unique feature ID}\n",
    "    \"\"\"\n",
    "    # TODO: We build a code map using ONLY train data. Think about how to construct validation/test sets using this.\n",
    "    df_digits = dataset['FEATURE'].unique()\n",
    "    codemap = {}\n",
    "    for i in range(0,len(df_digits)):\n",
    "        codemap[df_digits[i]] = i\n",
    "\n",
    "\n",
    "    return codemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding diagnoses data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and etl on diagnoses\n",
    "diagnoses = pd.read_csv(f\"{path}DIAGNOSES_ICD.csv.gz\")\n",
    "# sample for the patients\n",
    "diagnoses = pd.merge(patients_sample.SUBJECT_ID,diagnoses)\n",
    "diagnoses = diagnoses[['SUBJECT_ID','ICD9_CODE']]\n",
    "diagnoses['VALUE'] = 1\n",
    "diagnoses[\"ICD9_CODE\"] = diagnoses[\"ICD9_CODE\"].apply(convert_icd9)\n",
    "diagnoses.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4074</td>\n",
       "      <td>038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4074</td>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4074</td>\n",
       "      <td>578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4074</td>\n",
       "      <td>427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4074</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139065</th>\n",
       "      <td>62212</td>\n",
       "      <td>790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139066</th>\n",
       "      <td>62212</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139067</th>\n",
       "      <td>62212</td>\n",
       "      <td>338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139068</th>\n",
       "      <td>62212</td>\n",
       "      <td>V15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139069</th>\n",
       "      <td>62212</td>\n",
       "      <td>V49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112056 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID ICD9_CODE  VALUE\n",
       "0             4074       038      1\n",
       "1             4074       785      1\n",
       "2             4074       578      1\n",
       "3             4074       427      1\n",
       "4             4074       428      1\n",
       "...            ...       ...    ...\n",
       "139065       62212       790      1\n",
       "139066       62212       781      1\n",
       "139067       62212       338      1\n",
       "139068       62212       V15      1\n",
       "139069       62212       V49      1\n",
       "\n",
       "[112056 rows x 3 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read and etl on lab_results\n",
    "# lab_results = pd.read_csv(f\"{path}LABEVENTS_SAMPLE.csv\")\n",
    "lab_results = pd.read_csv(f\"{path}LABEVENTS.csv.gz\")\n",
    "lab_results = pd.merge(patients_sample.SUBJECT_ID,lab_results)\n",
    "# lab_results.to_csv(\"LABEVENTS_SAMPLE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roughly 20% of these items have null in the HADM ID\n",
    "lab_results = lab_results[['SUBJECT_ID','ITEMID','VALUE']]\n",
    "#making sure lab_results has different item_id than diagnostics. appending a code 200 to the itemIDs\n",
    "lab_results['ITEMID'] = lab_results['ITEMID']+20000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20050802</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>20050804</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20050806</td>\n",
       "      <td>105.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>20050808</td>\n",
       "      <td>1.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>20050809</td>\n",
       "      <td>94.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555449</th>\n",
       "      <td>99995</td>\n",
       "      <td>20051491</td>\n",
       "      <td>5.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555450</th>\n",
       "      <td>99995</td>\n",
       "      <td>20051492</td>\n",
       "      <td>30.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555451</th>\n",
       "      <td>99995</td>\n",
       "      <td>20051493</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555452</th>\n",
       "      <td>99995</td>\n",
       "      <td>20051498</td>\n",
       "      <td>1.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555453</th>\n",
       "      <td>99995</td>\n",
       "      <td>20051516</td>\n",
       "      <td>24.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555454 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID    ITEMID    VALUE\n",
       "0               11  20050802    2.000\n",
       "1               11  20050804   25.000\n",
       "2               11  20050806  105.000\n",
       "3               11  20050808    1.090\n",
       "4               11  20050809   94.000\n",
       "...            ...       ...      ...\n",
       "555449       99995  20051491    5.750\n",
       "555450       99995  20051492   30.000\n",
       "555451       99995  20051493   13.000\n",
       "555452       99995  20051498    1.019\n",
       "555453       99995  20051516   24.000\n",
       "\n",
       "[555454 rows x 3 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take average value for lab_results\n",
    "lab_results = lab_results.dropna()\n",
    "#keep only numeric values, removing things like 'not done'\n",
    "def is_a_number(x):\n",
    "    try:\n",
    "        float(x.strip())\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "#     if x in [' ','.']:\n",
    "#         return False\n",
    "#     for char in x.strip():\n",
    "#         if (not char in ['.',' ','1','2','3','4','5','6','7','8','9','0']):\n",
    "#             return False\n",
    "    return True\n",
    "lab_results = lab_results.loc[lab_results['VALUE'].apply(is_a_number),:]\n",
    "lab_results['VALUE'] = pd.to_numeric(lab_results['VALUE'])\n",
    "\n",
    "#keep average of values (can use more sophisticated methods later on)\n",
    "lab_results = lab_results.groupby(['SUBJECT_ID','ITEMID']).mean().reset_index()\n",
    "lab_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microbiology Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reading in data similar to lab_results, like microbiology events\n",
    "#NOTE: Does not seem to help at all\n",
    "mb_events = pd.read_csv(f\"{path}MICROBIOLOGYEVENTS.csv.gz\")\n",
    "mb_events = pd.merge(patients_sample.SUBJECT_ID,mb_events)\n",
    "mb_events = mb_events[['SUBJECT_ID','AB_ITEMID','INTERPRETATION']]\n",
    "mb_events.dropna(inplace= True)\n",
    "\n",
    "#transform seperate boolean values for Resistant, intermediate and Sensitive. \n",
    "mb_events.loc[mb_events.INTERPRETATION == 'R','AB_ITEMID'] += 31000000\n",
    "mb_events.loc[mb_events.INTERPRETATION == 'S','AB_ITEMID'] += 32000000\n",
    "mb_events.loc[mb_events.INTERPRETATION == 'I','AB_ITEMID'] += 33000000\n",
    "\n",
    "mb_events = mb_events.loc[mb_events.INTERPRETATION != 'P']\n",
    "mb_events.INTERPRETATION = 1\n",
    "mb_events.drop_duplicates(inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL on admissions\n",
    "#feature is the admission type and value is the time spent\n",
    "admissions = pd.read_csv(f\"{path}ADMISSIONS.csv.gz\")\n",
    "admissions = pd.merge(patients_sample.SUBJECT_ID,admissions)\n",
    "\n",
    "admissions['TIME_SPENT'] = pd.to_timedelta(pd.to_datetime(admissions.DISCHTIME)-  pd.to_datetime(admissions.ADMITTIME)).dt.total_seconds()/3600\n",
    "admissions['FEATURE'] = admissions.ADMISSION_TYPE.apply(lambda x: 40000000 + ord(x[0])*100+ord(x[1]))\n",
    "admissions = admissions[['SUBJECT_ID','FEATURE','TIME_SPENT']]\n",
    "\n",
    "admissions = admissions.groupby(['SUBJECT_ID','FEATURE']).aggregate('sum').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>TIME_SPENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>40006977</td>\n",
       "      <td>612.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>40006977</td>\n",
       "      <td>27.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>40006977</td>\n",
       "      <td>167.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>40007869</td>\n",
       "      <td>64.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>40007869</td>\n",
       "      <td>234.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510</th>\n",
       "      <td>99928</td>\n",
       "      <td>40006977</td>\n",
       "      <td>45.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10511</th>\n",
       "      <td>99935</td>\n",
       "      <td>40006977</td>\n",
       "      <td>5.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10512</th>\n",
       "      <td>99944</td>\n",
       "      <td>40006977</td>\n",
       "      <td>116.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>99985</td>\n",
       "      <td>40006977</td>\n",
       "      <td>398.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10514</th>\n",
       "      <td>99995</td>\n",
       "      <td>40006976</td>\n",
       "      <td>77.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID   FEATURE  TIME_SPENT\n",
       "0              11  40006977  612.700000\n",
       "1              22  40006977   27.466667\n",
       "2              26  40006977  167.733333\n",
       "3              27  40007869   64.483333\n",
       "4              39  40007869  234.100000\n",
       "...           ...       ...         ...\n",
       "10510       99928  40006977   45.883333\n",
       "10511       99935  40006977    5.016667\n",
       "10512       99944  40006977  116.516667\n",
       "10513       99985  40006977  398.300000\n",
       "10514       99995  40006976   77.250000\n",
       "\n",
       "[10515 rows x 3 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "This step will\n",
    "- merge all the features together\n",
    "- give them unique feature_ids by building a codemape\n",
    "- scale the features by their maximums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.245283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.160377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  FEATURE     VALUE\n",
       "0          11        0  0.075472\n",
       "1          22        0  0.000000\n",
       "2          39        0 -0.105660\n",
       "3          71        0 -0.245283\n",
       "4          87        0 -0.160377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#merging diagnosis and lab_results\n",
    "lab_results.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "diagnoses.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "mb_events.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "admissions.columns = ['SUBJECT_ID','FEATURE','VALUE']\n",
    "\n",
    "features = pd.concat([lab_results,diagnoses,mb_events,admissions])\n",
    "\n",
    "#get rid of missing values\n",
    "features = features.dropna()\n",
    "\n",
    "#apply codemap to features\n",
    "codemap = build_codemap(features)\n",
    "features['FEATURE'] = features['FEATURE'].map(codemap)\n",
    "features['VALUE'] = features.VALUE.round(6)\n",
    "\n",
    "#scale features\n",
    "max_features = features.groupby(['FEATURE']).aggregate('max').reset_index()\n",
    "features = features.merge(max_features,on = 'FEATURE', suffixes=['', '_MAX'])\n",
    "features['VALUE'] = features['VALUE']/features['VALUE_MAX']\n",
    "features = features[['SUBJECT_ID','FEATURE','VALUE']]\n",
    "features = features.dropna()\n",
    "display(features[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUBJECT_ID\n",
       "4074     1\n",
       "90889    0\n",
       "72753    0\n",
       "64908    0\n",
       "70273    0\n",
       "Name: DEAD, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create mortality table\n",
    "mortality = patients_sample.copy()\n",
    "mortality['DEAD'] = 1- mortality['DOD_SSN'].isna()\n",
    "mortality.index = mortality.SUBJECT_ID\n",
    "mortality = mortality['DEAD']\n",
    "\n",
    "display(mortality[0:5])\n",
    "mortality = mortality.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data prior to model training\n",
    "The data will be saved in an SVM_light format for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn patient_features into an svm_light format\n",
    "features['F2V'] = list(zip(features.FEATURE,features.VALUE))\n",
    "features_lists = features.groupby(['SUBJECT_ID'])['F2V'].apply(list)\n",
    "# features_lists = pd.DataFrame(features_lists).reset_index()\n",
    "features_lists = features_lists.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8759915"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # function to help output data\n",
    "def create_svmlite(patient_features, mortality, type):\n",
    "    patient_ids = list(patient_features.keys())\n",
    "    patient_ids.sort()\n",
    "    d1 = \"\"\n",
    "    for id in patient_ids:\n",
    "        patient_features[id].sort()\n",
    "        features = ''\n",
    "        for feature in patient_features[id]:\n",
    "            features += f\" {str(int(feature[0]))}:\" + \"{:.6f}\".format(feature[1])\n",
    "        if type == 1: d1 += f\"{mortality[id]}{features} \\n\"\n",
    "        if type == 2: d1 += f\"{int(id)} {mortality[id]}{features} \\n\"\n",
    "    # print(d1)\n",
    "\n",
    "    return d1\n",
    "# create_svmlite(features_lists,mortality,2)\n",
    "deliverable1 = open(f\"{path}svm_light/features.train\", 'wb')\n",
    "deliverable1.write(bytes((create_svmlite(features_lists, mortality, 1)), 'UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: Y_pred,Y_true\n",
    "# output: accuracy, auc, precision, recall, f1-score\n",
    "def classification_metrics(Y_pred, Y_true):\n",
    "    # TODO: Calculate the above mentioned metrics\n",
    "    acc = accuracy_score(Y_pred, Y_true)\n",
    "    auc_ = roc_auc_score(Y_pred, Y_true)\n",
    "    precision = precision_score(Y_pred, Y_true)\n",
    "    recall = recall_score(Y_pred, Y_true)\n",
    "    f1score = f1_score(Y_pred, Y_true)\n",
    "    # NOTE: It is important to provide the output in the same order\n",
    "    return acc, auc_, precision, recall, f1score\n",
    "# input: Name of classifier, predicted labels, actual labels\n",
    "def display_metrics(classifierName, Y_pred, Y_true):\n",
    "    print(\"______________________________________________\")\n",
    "    print((\"Classifier: \" + classifierName))\n",
    "    acc, auc_, precision, recall, f1score = classification_metrics(Y_pred, Y_true)\n",
    "    print((\"Accuracy: \" + str(acc)))\n",
    "    print((\"AUC: \" + str(auc_)))\n",
    "    print((\"Precision: \" + str(precision)))\n",
    "    print((\"Recall: \" + str(recall)))\n",
    "    print((\"F1-score: \" + str(f1score)))\n",
    "    print(\"______________________________________________\")\n",
    "    print(\"\")\n",
    "\n",
    "# input: X_train, Y_train and X_test\n",
    "# output: Y_pred\n",
    "def logistic_regression_pred(X_train, Y_train, X_test):\n",
    "    log_model = LogisticRegression(random_state=1)\n",
    "    log_model.fit(X_train, Y_train)\n",
    "    Y_pred = log_model.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "def decisionTree_pred(X_train, Y_train, X_test):\n",
    "    model = DecisionTreeClassifier(nrandom_state=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "X_train, Y_train = load_svmlight_file(f\"{path}svm_light/features.train\", n_features=3190)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(X_train,test_size = 0.2,random_state = 1)\n",
    "Y_train, Y_test = train_test_split(Y_train,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassan/opt/anaconda3/envs/Homework1/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.8025\n",
      "AUC: 0.7647675196112008\n",
      "Precision: 0.5783132530120482\n",
      "Recall: 0.691358024691358\n",
      "F1-score: 0.6298031865042173\n",
      "______________________________________________\n",
      "\n",
      "______________________________________________\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.7325\n",
      "AUC: 0.6748667998667999\n",
      "Precision: 0.53184165232358\n",
      "Recall: 0.5402097902097902\n",
      "F1-score: 0.5359930615784909\n",
      "______________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "display_metrics(\"Logistic Regression\", logistic_regression_pred(X_train, Y_train, X_test), Y_test)\n",
    "# display_metrics(\"SVM\", svm_pred(X_train, Y_train, X_test), Y_test)\n",
    "display_metrics(\"Decision Tree\", decisionTree_pred(X_train, Y_train, X_test), Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  },
  "kernelspec": {
   "display_name": "Python [conda env:Homework1]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
